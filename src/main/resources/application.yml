chat:
  implementation: ${IMPL:local}
spring:
  cloud:
    openfeign:
      client:
        config:
          default:
            loggerLevel: basic
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        model: gpt-oss:20b # gpt-oss:20b # nomic-embed-text:latest({"error":"\"nomic-embed-text:latest\" does not support chat"})
        options:
          temperature: 0.6 # Controls randomness in text generation (0.0 = deterministic, 1.0 = maximum randomness)
          top-p: 0.9 # Controls diversity via nucleus sampling (1.0 = consider all tokens, 0.1 = consider only top 10% probable tokens)
      embedding:
        options:
          temperature: 0.0
          model: nomic-embed-text
ollama:
  base-url: https://ollama.com
  api-key: ${OLLAMA_API_KEY}
server:
  port: ${PORT:8080}
# Telegram API
bot:
  name: ${BOT_NAME:WeatherForTomorrowBot}
  token: ${BOT_TOKEN}
  chatId: ${BOT_CHAT_ID}
# https://openweathermap.org/
open:
  weather:
    key: ${OPEN_API_KEY}
    url:
      base-url: ${OPEN_API_BASE_URL:https://api.openweathermap.org/data/2.5}
    parameters:
      current: /weather
      forecast: /forecast
      city: Minsk
      mode: json
      units: metric
      lang: en
      cnt: 4
# Actuator
management:
  endpoints:
    web:
      exposure:
        include: [ "*", "prometheus" ]
  endpoint:
    prometheus:
      enabled: true
  metrics:
    tags:
      application: weather-bot
    export: { }
  prometheus:
    metrics:
      export:
        enabled: true
# Logging
logging:
  level:
    com.gmail.arthurstrokov.weather: DEBUG
