chat:
  implementation: ${IMPL:local}
spring:
  cloud:
    openfeign:
      client:
        config:
          default:
            loggerLevel: basic
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        model: gpt-oss:20b # gpt-oss:20b # nomic-embed-text:latest({"error":"\"nomic-embed-text:latest\" does not support chat"})
        options:
          temperature: 0.6 # Controls randomness in text generation (0.0 = deterministic, 1.0 = maximum randomness)
          top-p: 0.9 # Controls diversity via nucleus sampling (1.0 = consider all tokens, 0.1 = consider only top 10% probable tokens)
      embedding:
        options:
          temperature: 0.0
          model: nomic-embed-text
ollama:
  base-url: https://ollama.com
  model: gpt-oss:120b-cloud
  api-key: test-key
# Telegram API
bot:
  name: WeatherForTomorrowBot
  token: token
  chatId: chatId
open:
  weather:
    key: key
    url:
      base-url: http://localhost:${wiremock.server.port}
    parameters:
      current: /weather
      forecast: /forecast
      city: Minsk
      mode: json
      units: metric
      lang: en
      cnt: 4
